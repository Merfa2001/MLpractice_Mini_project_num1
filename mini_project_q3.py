# -*- coding: utf-8 -*-
"""mini_project_q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12HWGCO1eWDDxSHBA75hcAOlIL1putlJS
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

# Load the dataset
file_path = '/content/drive/My Drive/heart_disease_health_indicators.csv'
data = pd.read_csv(file_path)

# Display the first few rows of the dataset to understand its structure
data.head()

# Selecting 100 samples from each class (0 and 1) of the 'HeartDiseaseorAttack' column
heart_disease_data = pd.read_csv('/content/drive/My Drive/heart_disease_health_indicators.csv')

# Samples where 'HeartDiseaseorAttack' is 1
class_1_samples = heart_disease_data[heart_disease_data['HeartDiseaseorAttack'] == 1].sample(n=100, random_state=11)

# Samples where 'HeartDiseaseorAttack' is 0
class_0_samples = heart_disease_data[heart_disease_data['HeartDiseaseorAttack'] == 0].sample(n=100, random_state=11)

# Combining the two sample sets into a new dataframe
combined_samples = pd.concat([class_1_samples, class_0_samples])

# Resetting the index of the new dataframe
combined_samples.reset_index(drop=True, inplace=True)

combined_samples.head()  # Displaying the first few rows of the new dataframe

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Assuming 'combined_samples' is your dataframe
X = combined_samples.drop('HeartDiseaseorAttack', axis=1)
y = combined_samples['HeartDiseaseorAttack']

# Splitting the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)

# Logistic Regression Model
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
log_reg_pred = log_reg.predict(X_test)
log_reg_accuracy = accuracy_score(y_test, log_reg_pred)

# Random Forest Classifier Model
rf_classifier = RandomForestClassifier()
rf_classifier.fit(X_train, y_train)
rf_pred = rf_classifier.predict(X_test)
rf_accuracy = accuracy_score(y_test, rf_pred)

# Displaying the results
print(f"Logistic Regression Accuracy: {log_reg_accuracy}")
print(f"Random Forest Classifier Accuracy: {rf_accuracy}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Logistic Regression function
def logistic_regression(X, y, lr=0.01, iterations=1000):
    m, n = X.shape
    X = np.hstack((np.ones((m, 1)), X))  # Adding bias term
    weights = np.zeros(n + 1)
    losses = []

    for _ in range(iterations):
        z = np.dot(X, weights)
        predictions = 1 / (1 + np.exp(-z))
        gradient = np.dot(X.T, (predictions - y)) / m
        weights -= lr * gradient
        loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))
        losses.append(loss)

    return weights, losses

# Load your data here
# heart_disease_data = pd.read_csv('/path/to/your/dataset.csv')
# X = combined_samples.drop('HeartDiseaseorAttack', axis=1).values
# y = combined_samples['HeartDiseaseorAttack'].values

# Split and scale your data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train the model
weights, losses = logistic_regression(X_train_scaled, y_train, lr=0.01, iterations=1000)

# Plotting the loss
plt.plot(losses)
plt.title('Loss Function over Iterations')
plt.xlabel('Iterations')
plt.ylabel('Loss')
plt.show()

from sklearn.metrics import roc_auc_score, roc_curve, auc
import matplotlib.pyplot as plt

# Assuming you already have trained models 'log_reg' and 'rf_classifier'
# and your test set 'X_test_scaled' and 'y_test'

# Predict probabilities for Logistic Regression
log_reg_probs = log_reg.predict_proba(X_test_scaled)[:, 1]
log_reg_auc = roc_auc_score(y_test, log_reg_probs)
print(f"Logistic Regression AUC-ROC: {log_reg_auc}")

# Predict probabilities for Random Forest
rf_probs = rf_classifier.predict_proba(X_test_scaled)[:, 1]
rf_auc = roc_auc_score(y_test, rf_probs)
print(f"Random Forest AUC-ROC: {rf_auc}")

# Function to plot ROC Curve
def plot_roc_curve(fpr, tpr, model_name, auc):
    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.2f})')
    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend()
    plt.show()

# Calculate ROC Curve for Logistic Regression
fpr_log, tpr_log, _ = roc_curve(y_test, log_reg_probs)
plot_roc_curve(fpr_log, tpr_log, 'Logistic Regression', log_reg_auc)

# Calculate ROC Curve for Random Forest
fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_probs)
plot_roc_curve(fpr_rf, tpr_rf, 'Random Forest', rf_auc)
#done