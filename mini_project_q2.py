# -*- coding: utf-8 -*-
"""mini_project_q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QrQa2KaVtcQEG18H_FFlikOS-TXlv2Wr

part1 :
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
file_path = '/content/drive/My Drive/data_banknote_authentication.txt'
df = pd.read_csv(file_path, header=None)
print (df)

"""part2:"""

from sklearn.model_selection import train_test_split  # Import statement for train_test_split
# Shuffle the dataset
df_shuffled = df.sample(frac=1, random_state=11)

# Split the dataset into training and evaluation sets (80/20 split)
train_set, eval_set = train_test_split(df_shuffled, test_size=0.2, random_state=11)

# Print the first few rows of the shuffled DataFrame (optional)
print("First few rows of shuffled DataFrame:")
print(df_shuffled.head())

# Print the size of the training and evaluation sets
print("\nSize of Training Set:", len(train_set))
print("Size of Evaluation Set:", len(eval_set))

"""part3:"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# Logistic Regression Functions

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def logistic_regression(X, weights, bias):
    return sigmoid(np.dot(X, weights) + bias)

def log_loss(y_true, y_pred):
    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))

def gradient_descent(X, y, weights, bias, learning_rate, epochs):
    losses = []
    for epoch in range(epochs):
        y_pred = logistic_regression(X, weights, bias)
        loss = log_loss(y, y_pred)
        losses.append(loss)

        dw = np.dot(X.T, (y_pred - y)) / len(y)
        db = np.sum(y_pred - y) / len(y)

        weights -= learning_rate * dw
        bias -= learning_rate * db
    return weights, bias, losses

def accuracy(y_true, y_pred):
    y_pred_label = np.round(y_pred)
    return np.mean(y_true == y_pred_label)

# Assuming you have already loaded your DataFrame as 'df'

# Splitting features and labels
X = df.iloc[:, :-1].values  # Features
y = df.iloc[:, -1].values  # Labels

# Split the data into training and testing sets (80/20 split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)

# Initialize weights and bias
weights = np.zeros(X_train.shape[1])
bias = 0

# Train the model
learning_rate = 0.01
epochs = 1000
weights, bias, losses = gradient_descent(X_train, y_train, weights, bias, learning_rate, epochs)

# Plot the loss function
plt.plot(losses)
plt.title('Loss Function over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()

# Evaluate the model on test data
y_pred_test = logistic_regression(X_test, weights, bias)
test_accuracy = accuracy(y_test, y_pred_test)
print("Accuracy on Test Data:", test_accuracy)

"""part4:"""

# Calculate the mean and standard deviation from the training data
mean = np.mean(X_train, axis=0)
std = np.std(X_train, axis=0)

# Standardize the training data
X_train_std = (X_train - mean) / std

# Standardize the test data using the same parameters
X_test_std = (X_test - mean) / std

print(mean)
print("*********")
print(std)
print("*********")
print(X_test_std)
print("*********")

"""part5:"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# Assuming df, logistic_regression, log_loss, gradient_descent, and accuracy functions are already defined

# Normalize the data
mean = np.mean(X_train, axis=0)
std = np.std(X_train, axis=0)
X_train_std = (X_train - mean) / std
X_test_std = (X_test - mean) / std

# Initialize weights and bias for the normalized data
weights_std = np.zeros(X_train_std.shape[1])
bias_std = 0

# Train the model on normalized data
learning_rate = 0.01
epochs = 1000
weights_std, bias_std, losses_std = gradient_descent(X_train_std, y_train, weights_std, bias_std, learning_rate, epochs)

# Plot the loss function for normalized data
plt.plot(losses_std)
plt.title('Loss Function over Epochs (Normalized Data)')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()

# Evaluate the model on normalized test data
y_pred_test_std = logistic_regression(X_test_std, weights_std, bias_std)
test_accuracy_std = accuracy(y_test, y_pred_test_std)
print("Accuracy on Normalized Test Data:", test_accuracy_std)

# Make predictions for five samples from the test set
sample_indices = np.random.choice(X_test_std.shape[0], 5, replace=False)
sample_predictions = logistic_regression(X_test_std[sample_indices], weights_std, bias_std)
sample_actual = y_test[sample_indices]

# Display predictions and actual data
for i, index in enumerate(sample_indices):
    print(f"Sample {i+1}:")
    print("Predicted Probability:", sample_predictions[i])
    print("Predicted Class:", 1 if sample_predictions[i] > 0.5 else 0)
    print("Actual Class:", sample_actual[i])
    print()

"""part6:"""

# Count the number of samples in each class
class_counts = df.iloc[:, -1].value_counts()
print("Class Counts:\n", class_counts)

# Check if the classes are balanced
is_balanced = class_counts.min() / class_counts.max() > 0.8  # Threshold for considering as balanced
print("Is the dataset balanced?", is_balanced)

"""part7:"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline

# Initialize the classifier with class weight adjustment
clf_weighted = LogisticRegression(class_weight='balanced', random_state=11)

# Or, use a resampling strategy like SMOTE
oversample = SMOTE()
clf_smote = Pipeline([('SMOTE', oversample), ('Logistic Regression', LogisticRegression(random_state=11))])

# Train and evaluate the model with class weight adjustment
clf_weighted.fit(X_train_std, y_train)
y_pred_weighted = clf_weighted.predict(X_test_std)
print("Evaluation with Class Weights:\n", classification_report(y_test, y_pred_weighted))

# Train and evaluate the model with SMOTE
clf_smote.fit(X_train_std, y_train)
y_pred_smote = clf_smote.predict(X_test_std)
print("Evaluation with SMOTE:\n", classification_report(y_test, y_pred_smote))
#done